{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:38.703691Z",
     "start_time": "2025-04-14T19:30:23.676368Z"
    }
   },
   "source": [
    "from tokenizer.BPE import tokenize, tokenizer\n",
    "import pickle as pkl\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torchaudio.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformer import TransformerLanguageModel\n",
    "import wandb\n",
    "from datetime import datetime"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenized dataset creation",
   "id": "3a1d16195e2b1453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:38.729588Z",
     "start_time": "2025-04-14T19:30:38.721834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "merges_path = os.path.join(current_dir, \"tokenizer\", \"merges.pkl\")\n",
    "vocab_path = os.path.join(current_dir, \"tokenizer\", \"vocabulary.pkl\")\n",
    "\n",
    "# Загрузка merges.pkl\n",
    "with open(merges_path, \"rb\") as f:\n",
    "    merges = pkl.load(f)\n",
    "    print(\"Загрузка merges.pkl успешна\")\n",
    "\n",
    "# Загрузка vocab.pkl\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pkl.load(f)\n",
    "    print(\"Загрузка vocabulary.pkl успешна\")\n",
    "\n",
    "text = 'HELLO MY NAME IS BILL'\n",
    "tokens = [vocab[0]] + tokenize(text, merges) + [vocab[1]]\n",
    "#print(tokens)\n",
    "#print(tokenizer.convert_tokens_to_string(tokens))"
   ],
   "id": "d8896b53892a218d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка merges.pkl успешна\n",
      "Загрузка vocabulary.pkl успешна\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:44.777813Z",
     "start_time": "2025-04-14T19:30:38.857022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.init(project='TransformerLM')\n",
    "config = {\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 64,\n",
    "    'embedding_dim': 64,\n",
    "    'dataset': \"LibriSpeech dev-clean\",\n",
    "    'vocab_size': len(vocab),\n",
    "}\n",
    "wandb.config.update(config)"
   ],
   "id": "3539065f3d01bd41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: roman-kuznetsov (roman-kuznetsov-bmstu-) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>D:\\PyCharmPrj\\VKProject\\LM\\wandb\\run-20250414_223043-rnb7zetp</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM/runs/rnb7zetp' target=\"_blank\">restful-thunder-13</a></strong> to <a href='https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM' target=\"_blank\">https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM/runs/rnb7zetp' target=\"_blank\">https://wandb.ai/roman-kuznetsov-bmstu-/TransformerLM/runs/rnb7zetp</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:52.092423Z",
     "start_time": "2025-04-14T19:30:44.792211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_to_id = {vocab[i]: i for i in range(len(vocab))}\n",
    "id_to_token = {i: vocab[i] for i in range(len(vocab))}\n",
    "\n",
    "data = datasets.LIBRISPEECH(\"../data\", url=\"dev-clean\", )\n",
    "corpus = []\n",
    "for i in range(2800):\n",
    "    try:\n",
    "        corpus.append(list(map(lambda x: token_to_id[x], [vocab[0]] + tokenize(data.__getitem__(i)[2], merges) + [vocab[1]])))\n",
    "    except IndexError as err:\n",
    "        break\n",
    "\n",
    "max_length = max(len(seq) for seq in corpus)\n",
    "print(max_length)\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, max_len):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.tensor(self.data[idx], dtype=torch.int16)\n",
    "        sample = sample[:self.max_len]\n",
    "        length = sample.shape[-1]\n",
    "        padding = torch.ones((self.max_len - sample.shape[-1])) * 2\n",
    "        sample = torch.cat((sample, padding), dim=0)\n",
    "        return torch.tensor(sample, dtype=torch.float), length\n",
    "\n",
    "dataset = TextDataset(corpus, max_length)\n",
    "\n",
    "train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2)\n",
    "\n",
    "# Создание тренировочного и валидационного датасетов\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "# Создание DataLoader-ов для тренировочного и валидационного датасетов\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"])"
   ],
   "id": "3162e102f1989c80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:33:02.150775Z",
     "start_time": "2025-04-14T19:33:02.147255Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_to_id)",
   "id": "db0c5c71aaa92007",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|startoftext|>': 0, '<|endoftext|>': 1, '<|padding|>': 2, \"'\": 3, 'A': 4, 'B': 5, 'C': 6, 'D': 7, 'E': 8, 'F': 9, 'G': 10, 'H': 11, 'I': 12, 'J': 13, 'K': 14, 'L': 15, 'M': 16, 'N': 17, 'O': 18, 'P': 19, 'Q': 20, 'R': 21, 'S': 22, 'T': 23, 'U': 24, 'V': 25, 'W': 26, 'X': 27, 'Y': 28, 'Z': 29, 'Ġ': 30, 'ĠT': 31, 'HE': 32, 'ĠA': 33, 'IN': 34, 'ĠTHE': 35, 'ĠW': 36, 'ĠS': 37, 'ĠO': 38, 'RE': 39, 'ND': 40, 'ĠH': 41, 'ER': 42, 'ĠB': 43, 'ĠM': 44, 'OU': 45, 'IT': 46, 'ĠF': 47, 'IS': 48, 'ĠC': 49, 'AT': 50, 'ED': 51, 'ĠAND': 52, 'ĠOF': 53, 'EN': 54, 'ON': 55, 'ING': 56, 'ĠTO': 57, 'ĠP': 58, 'OR': 59, 'ES': 60, 'ĠD': 61, 'ĠTH': 62, 'ĠL': 63, 'AN': 64, 'AS': 65, 'ĠIN': 66, 'AR': 67, 'LL': 68, 'ĠN': 69, 'ĠHE': 70, 'ĠG': 71, 'AD': 72, 'LE': 73, 'OM': 74, 'ĠE': 75, 'ĠBE': 76, 'OT': 77, 'UT': 78, 'IC': 79, 'OW': 80, 'LY': 81, 'SE': 82, 'ĠI': 83, 'ST': 84, 'VE': 85, 'ĠWAS': 86, 'LD': 87, 'ĠWH': 88, 'GH': 89, 'ĠIT': 90, 'ĠTHAT': 91, 'ĠON': 92, 'ĠU': 93, 'ENT': 94, 'AL': 95, 'THE': 96, 'ID': 97, 'IM': 98, 'VER': 99, 'ĠHIS': 100, 'ĠY': 101, 'ĠRE': 102, 'IR': 103, 'ITH': 104, 'CE': 105, 'ION': 106, 'ĠR': 107, 'ĠWITH': 108, 'ĠWE': 109, 'ET': 110, 'ĠAS': 111, 'ĠFOR': 112, 'AY': 113, 'ĠST': 114, 'UR': 115, 'ĠHAD': 116, 'GHT': 117, 'ĠYOU': 118, 'OO': 119, 'ĠNOT': 120, 'TER': 121, 'ĠAN': 122, 'AND': 123, 'AC': 124, 'ĠIS': 125, 'ĠAT': 126, 'ĠSE': 127}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:31:49.859888Z",
     "start_time": "2025-04-14T19:31:49.840939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, el in enumerate(val_loader):\n",
    "    if i < 4:\n",
    "        print(el)\n",
    "    else:\n",
    "        break"
   ],
   "id": "261643c91b8b8bb5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_78916\\1362571734.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sample, dtype=torch.float), length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  0.,  96.,  38.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,   6.,  21.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  22.,  11.,  ...,   2.,   2.,   2.],\n",
      "        ...,\n",
      "        [  0.,  46., 102.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  55.,  35.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  22.,  32.,  ...,   2.,   2.,   2.]]), tensor([ 41,  38, 152,  56, 212,  52,  52,  26, 109,  19,  64,  79,   9,  46,\n",
      "         41,  46,  52,  26,  73,  17,  17,  41,  66,  52,  34,  84,  48,  17,\n",
      "         77,  66,  16,   7,  20,  84,  32,  35,  73, 116,  59,  21,  60,  32,\n",
      "         49,  65,  26,  96,  65, 115,  10,  37,  41,  43,  33,  80,  43,  65,\n",
      "        163, 109,  69,  26,  63,  74,  47,  24])]\n",
      "[tensor([[ 0., 16., 24.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 26., 32.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 12., 63.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [ 0.,  7., 18.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 45., 21.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 46.,  3.,  ...,  2.,  2.,  2.]]), tensor([ 80,  21,  50,  45,  57,  39,  93,  28,  19,  21,  51,  35,  67,  16,\n",
      "         24,  30,  88,  32, 100,  95,  23,  81,  40,  32,  12,  77,  42, 136,\n",
      "         21,  71,  43,  25,  74,  67,  59, 129,  42,  20,  50,  38,  74,  40,\n",
      "         51,  84,  23, 143,  58,  49,  58,  34,  69,  50,  86,  27,  42,  38,\n",
      "         38, 128,  90, 136,  52,  31,  22,  35])]\n",
      "[tensor([[  0., 115.,  22.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  65.,  19.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  96.,  17.,  ...,   2.,   2.,   2.],\n",
      "        ...,\n",
      "        [  0.,  46.,  86.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,   5.,  78.,  ...,   2.,   2.,   2.],\n",
      "        [  0.,  22.,  11.,  ...,   2.,   2.,   2.]]), tensor([ 46,  40,  61,  92,  50,  34,  33,  75,  26, 106, 102, 169,  22,  66,\n",
      "         80,  54,  44,  40,  47,  29,  58,  87,  20,  41, 136, 173,  18,  58,\n",
      "         28,  81,  37,  35,  50,  55, 144,  40,  42, 107,  59,  34,  17, 104,\n",
      "         55,  31,  13,  46,  31,  17,  67,  23, 138,  12,   8,  42, 139,  49,\n",
      "         28,  17, 111,  79,  81,  44, 128,   8])]\n",
      "[tensor([[ 0., 12., 58.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 26.,  8.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 12.,  3.,  ...,  2.,  2.,  2.],\n",
      "        ...,\n",
      "        [ 0., 22., 18.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 45., 21.,  ...,  2.,  2.,  2.],\n",
      "        [ 0., 12., 37.,  ...,  2.,  2.,  2.]]), tensor([ 58,  64,  24,  34,  19,  51,  20,  15,  23,  54,  21,  18,  26,  27,\n",
      "         79,  68,  28,  36,  42,  34,  27,  48,  20,  78,  43, 180,  50, 121,\n",
      "         26,  49,  21,  21,  33,  91,  21, 206,  18,  34,  47,  31,  99,  85,\n",
      "         41,  27, 115,  34,  17,  72,  29,  44, 103,  73,  70,  44,  12,  66,\n",
      "         46,  51, 121,  29,   9,  40,  28,  85])]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:52.115953Z",
     "start_time": "2025-04-14T19:30:52.112348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def length_to_mask(data, lengths, dtype=None):\n",
    "    batch_size, max_length = data.size(0), max(lengths)\n",
    "\n",
    "    tgt_mask = torch.triu(torch.ones((max_length, max_length), device=device) == 1).transpose(0, 1)\n",
    "    tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n",
    "\n",
    "    # Создание key_padding_mask (2D)\n",
    "    key_padding_mask = (torch.arange(max_length).expand(batch_size, max_length) >= lengths.unsqueeze(1))\n",
    "\n",
    "    # Приведение к нужному типу, если указано\n",
    "    if dtype is not None:\n",
    "        key_padding_mask = key_padding_mask.to(dtype=dtype)\n",
    "\n",
    "    return tgt_mask, key_padding_mask"
   ],
   "id": "be73f2ce060556f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:52.310546Z",
     "start_time": "2025-04-14T19:30:52.117947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Параметры модели\n",
    "vocab_size = config['vocab_size']\n",
    "embedding_dim = config['embedding_dim']\n",
    "dim_feedforward = 64\n",
    "num_heads = 8\n",
    "num_layers = 4\n",
    "num_epochs = config['epochs']\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerLanguageModel(vocab_size, embedding_dim, num_heads, dim_feedforward, num_layers).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "warmup_steps = 0.1 * total_steps\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)"
   ],
   "id": "685d78a0975ce242",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:52.329046Z",
     "start_time": "2025-04-14T19:30:52.322388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(epoch_index, model, training_loader, scheduler, optimizer, loss_fn):\n",
    "    running_loss = 0.\n",
    "    train_loss = 0.\n",
    "\n",
    "    i = 0\n",
    "    cnt_right_answers = 0\n",
    "    cnt_answers = 0\n",
    "\n",
    "    for data, lengths in training_loader:\n",
    "        input_data = data.to(device)\n",
    "        tgt_mask, tgt_key_padding_mask = length_to_mask(input_data, lengths)\n",
    "        tgt_mask, tgt_key_padding_mask = tgt_mask.to(device), tgt_key_padding_mask.to(device)\n",
    "        print(torch.max(lengths))\n",
    "\n",
    "        if epoch_index != -1:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        tgt_y = input_data[:, 1:]\n",
    "\n",
    "        outputs, _ = model(input_data[:, :-1].to(int), tgt_mask=tgt_mask, lengths=lengths, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "        answers = outputs.argmax(axis=-1)\n",
    "        loss = loss_fn(outputs, tgt_y)\n",
    "        if epoch_index != -1:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        if i % 10 == 9 and epoch_index != -1:\n",
    "            last_loss = running_loss / 10 # loss per batch\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            wandb.log({'Loss': last_loss, \"Train\": tb_x})\n",
    "            running_loss = 0.\n",
    "\n",
    "        if i % 10 == 0 and scheduler is not None:\n",
    "            wandb.log({'Scheduler LR': optimizer.param_groups[0][\"lr\"], \"Train\": tb_x})\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        cnt_answers += tgt_y.shape[0]\n",
    "        cnt_right_answers += (answers == tgt_y).sum().item()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    train_loss = train_loss / len(training_loader)\n",
    "    wandb.log({'Accuracy': cnt_right_answers / cnt_answers, \"Train\": epoch_index + 1})\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def validation(val_dataloader):\n",
    "    val_loss = 0.0\n",
    "\n",
    "    cnt_answers = 0\n",
    "    cnt_right_answers = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dataloader):\n",
    "            input_data, lengths = vdata\n",
    "            tgt_mask, tgt_key_padding_mask = length_to_mask(input_data, lengths)\n",
    "            tgt_mask, tgt_key_padding_mask = tgt_mask.to(device), tgt_key_padding_mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            input_data = input_data.to(device)\n",
    "            labels = input_data[:, 1:].to(device)\n",
    "            outputs, _ = model(input_data[:, :-1].to(int), tgt_mask=tgt_mask, lengths=lengths, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "\n",
    "            vloss = criterion(outputs, labels)\n",
    "            val_loss += vloss.item()\n",
    "            answers = outputs.argmax(axis=-1)\n",
    "\n",
    "            cnt_answers += labels.shape[0]\n",
    "            cnt_right_answers += (answers == labels).sum().item()\n",
    "\n",
    "            del input_data, labels, lengths\n",
    "\n",
    "    val_loss = val_loss / len(val_dataloader)\n",
    "    print(\"VAL LOSS =\", val_loss)\n",
    "    return val_loss, cnt_right_answers / cnt_answers"
   ],
   "id": "d1316ba572adb871",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T19:30:53.097541Z",
     "start_time": "2025-04-14T19:30:52.352875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_vloss = 1_000_000.\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "for epoch_number in range(num_epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    model.train()\n",
    "    train_loss = train_one_epoch(\n",
    "        epoch_index=epoch_number,\n",
    "        model=model,\n",
    "        training_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        loss_fn=criterion,)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_acc = validation(val_loader)\n",
    "\n",
    "    wandb.log('Loss/valid', val_loss, epoch_number + 1)\n",
    "    wandb.log('Accuracy/valid', val_acc, epoch_number + 1)\n",
    "    if val_loss < best_vloss:\n",
    "        best_vloss = val_loss\n",
    "        model_path = os.path.join(\"../best_models/transformer\", 'model_{}_{}'.format(epoch_number + 1, timestamp))\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "wandb.finish()"
   ],
   "id": "1a8d6e22d387b3ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_78916\\1362571734.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(sample, dtype=torch.float), length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(277)\n",
      "torch.Size([277, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 512, 8]' is invalid for input of size 1134592",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEPOCH \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch_number \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m      8\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m----> 9\u001B[0m train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepoch_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m     18\u001B[0m val_loss, val_acc \u001B[38;5;241m=\u001B[39m validation(val_loader)\n",
      "Cell \u001B[1;32mIn[7], line 20\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(epoch_index, model, training_loader, scheduler, optimizer, loss_fn)\u001B[0m\n\u001B[0;32m     16\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     18\u001B[0m tgt_y \u001B[38;5;241m=\u001B[39m input_data[:, \u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m---> 20\u001B[0m outputs, _ \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlengths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m answers \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     23\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs, tgt_y)\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\VKProject\\LM\\transformer.py:56\u001B[0m, in \u001B[0;36mTransformerLanguageModel.forward\u001B[1;34m(self, tgt, tgt_mask, lengths, tgt_key_padding_mask)\u001B[0m\n\u001B[0;32m     53\u001B[0m memory \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((tgt\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m1\u001B[39m), tgt\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model), device\u001B[38;5;241m=\u001B[39mtgt\u001B[38;5;241m.\u001B[39mdevice)  \u001B[38;5;66;03m# Пустой источник\u001B[39;00m\n\u001B[0;32m     54\u001B[0m memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_encoder(memory)\n\u001B[1;32m---> 56\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer_decoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtgt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:613\u001B[0m, in \u001B[0;36mTransformerDecoder.forward\u001B[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001B[0m\n\u001B[0;32m    610\u001B[0m tgt_is_causal \u001B[38;5;241m=\u001B[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m--> 613\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    614\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    615\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    616\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtgt_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    617\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    618\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_key_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    619\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_key_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_key_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    620\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtgt_is_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtgt_is_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_is_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmemory_is_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    625\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm(output)\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1112\u001B[0m, in \u001B[0;36mTransformerDecoderLayer.forward\u001B[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1107\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(\n\u001B[0;32m   1108\u001B[0m         x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001B[0;32m   1109\u001B[0m     )\n\u001B[0;32m   1110\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(\n\u001B[0;32m   1111\u001B[0m         x\n\u001B[1;32m-> 1112\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mha_block\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m            \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_key_padding_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmemory_is_causal\u001B[49m\n\u001B[0;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1115\u001B[0m     )\n\u001B[0;32m   1116\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm3(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(x))\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1148\u001B[0m, in \u001B[0;36mTransformerDecoderLayer._mha_block\u001B[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_mha_block\u001B[39m(\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1142\u001B[0m     x: Tensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1146\u001B[0m     is_causal: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1147\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m-> 1148\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultihead_attn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneed_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout2(x)\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001B[0m, in \u001B[0;36mMultiheadAttention.forward\u001B[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   1347\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmulti_head_attention_forward(\n\u001B[0;32m   1348\u001B[0m         query,\n\u001B[0;32m   1349\u001B[0m         key,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1370\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal,\n\u001B[0;32m   1371\u001B[0m     )\n\u001B[0;32m   1372\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1373\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_head_attention_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1374\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1375\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1376\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1377\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1378\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1380\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_k\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1382\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_v\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1383\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_zero_attn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1384\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1385\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1386\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneed_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mneed_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1391\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage_attn_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage_attn_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1393\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;129;01mand\u001B[39;00m is_batched:\n\u001B[0;32m   1395\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m), attn_output_weights\n",
      "File \u001B[1;32mD:\\PyCharmPrj\\ML\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:6298\u001B[0m, in \u001B[0;36mmulti_head_attention_forward\u001B[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   6296\u001B[0m q \u001B[38;5;241m=\u001B[39m q\u001B[38;5;241m.\u001B[39mview(tgt_len, bsz \u001B[38;5;241m*\u001B[39m num_heads, head_dim)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m   6297\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m static_k \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 6298\u001B[0m     k \u001B[38;5;241m=\u001B[39m \u001B[43mk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbsz\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m   6299\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6300\u001B[0m     \u001B[38;5;66;03m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001B[39;00m\n\u001B[0;32m   6301\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m   6302\u001B[0m         static_k\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m bsz \u001B[38;5;241m*\u001B[39m num_heads\n\u001B[0;32m   6303\u001B[0m     ), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpecting static_k.size(0) of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbsz\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39mnum_heads\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstatic_k\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[64, 512, 8]' is invalid for input of size 1134592"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
